{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccfb694",
   "metadata": {},
   "source": [
    "### Web Scraping Congress\n",
    "This file is a script that webscrapes information from voting bills in the US congress during 2020.\n",
    "\n",
    "We start by importing all needed packages. (Write \"!pip install <package>\" to install missing packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e877bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44af3d7",
   "metadata": {},
   "source": [
    "Collect all urls to be scraped!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10a2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(2,254):\n",
    "    url_list.append(f'https://clerk.house.gov/Votes/2020{i}?Page=2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64f3d0",
   "metadata": {},
   "source": [
    "Scrape 'em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a191bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "members = []\n",
    "parties = []\n",
    "states = []\n",
    "votes = []\n",
    "\n",
    "for i,url in enumerate(url_list):\n",
    "    page = requests.get(url)\n",
    "    soup = BS(page.content, 'html.parser')\n",
    "\n",
    "    member_list = []\n",
    "    party_list = []\n",
    "    state_list = []\n",
    "    vote_list = []\n",
    "\n",
    "    member_td = soup.find_all('td',attrs={\"data-label\": \"member\",\"hidden\":True})\n",
    "    party_td = soup.find_all('td',attrs={\"data-label\": \"party\"})\n",
    "    state_td = soup.find_all('td',attrs={\"data-label\": \"state\"})\n",
    "    state_td = state_td[1::2]\n",
    "    vote_td = soup.find_all('td',attrs={\"data-label\": \"vote\"})\n",
    "    for mem_idx in range(len(vote_td)):\n",
    "        vote_list.append(str(vote_td[mem_idx]).replace('<td data-label=\"vote\">', \"\").replace('</td>',''))\n",
    "        state_list.append(str(state_td[mem_idx]).replace('<td class=\"visible-sm visible-xs\" data-label=\"state\">',\"\").replace('</td>',\"\"))\n",
    "        party_list.append(str(party_td[mem_idx]).replace('<td data-label=\"party\">','').replace('</td>',''))\n",
    "        member_list.append(str(member_td[mem_idx]).replace('<td data-label=\"member\" hidden=\"\">','').replace('</td>',''))\n",
    "    members.append(member_list)\n",
    "    parties.append(party_list)\n",
    "    states.append(state_list)\n",
    "    votes.append(vote_list)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c74fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_members = []\n",
    "for i in members:\n",
    "    all_members = all_members+i\n",
    "all_members = np.unique(all_members)\n",
    "\n",
    "members=a\n",
    "states=b\n",
    "votes=c\n",
    "parties=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "611c3e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, bill in enumerate(members):\n",
    "    for member in all_members:\n",
    "        if member not in bill:\n",
    "            members[i] = sorted(members[i]+[member])\n",
    "            for pos, dude in enumerate(members[i]):\n",
    "                if dude == member:\n",
    "                    votes[i].insert(pos, 'NP')\n",
    "                    parties[i].insert(pos,'NP')\n",
    "                    states[i].insert(pos,'NP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f533893",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = np.array(votes)\n",
    "members = np.array(members)\n",
    "states = np.array(states)\n",
    "parties = np.array(parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88e54876",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = len(members[0])\n",
    "graph = np.arange(lm)\n",
    "graph.shape = (442,1)\n",
    "for i in range(len(votes)):\n",
    "    for j in range(len(votes[i])):\n",
    "        if votes[i][j] == 'Yea' or votes[i][j] == 'Aye':\n",
    "            votes[i][j] = 1\n",
    "        if votes[i][j] == 'Nay' or votes[i][j] == 'No':\n",
    "            votes[i][j] = 0\n",
    "        if votes[i][j] == 'Not Voting' or votes[i][j] == 'Present':\n",
    "            votes[i][j] = 2\n",
    "        if votes[i][j] == 'NP':\n",
    "            votes[i][j] = 3    \n",
    "    graph = np.concatenate((graph, np.reshape(votes[i], (442, 1))),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0d0d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "graph = graph[:,1:]\n",
    "graph = pd.DataFrame(graph)\n",
    "graph.to_csv('2020_congress_graph.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a06fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "US_states = np.empty(lm, dtype='<U4')\n",
    "for i in range(len(states)):\n",
    "    for j in range(len(states[i])):\n",
    "        if states[i][j] != 'NP':\n",
    "            US_states[j] = str(states[i][j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84c4ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "US_parties = np.empty(lm,dtype='<U20')\n",
    "for i in range(len(parties)):\n",
    "    for j in range(len(parties[i])):\n",
    "        if parties[i][j] != 'NP':\n",
    "            US_parties[j] = str(parties[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b41d75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.concatenate((np.reshape(US_states, (442, 1)),np.reshape(US_parties, (442, 1))),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61f8fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame(metadata,columns=['State','Party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5150676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.to_csv('2020_congress_metadata.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9533c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
